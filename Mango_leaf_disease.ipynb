{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adamusengamana/Mango_Leaf_Disease_Classification/blob/main/Mango_leaf_disease.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp96C7WmVxzD"
      },
      "source": [
        "#**Mango Leaf Disease Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ApcirmNVxzM"
      },
      "source": [
        "<center>\n",
        "    <img src='https://1.bp.blogspot.com/-3NVFdJH0sY4/X1UbWI9xKMI/AAAAAAAADDM/qYt_kDpkJbw72ZXbmqz1u64X-VMEfIhlACLcBGAsYHQ/s640/Mango%2Banthracnose.jpg'>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huvr3bkXVxzM"
      },
      "source": [
        "   <a id='top'></a>\n",
        "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\"></div>\n",
        "\n",
        "## <div style=\"background-color:#B21010;font-family:sans-serif;color:#FFF9ED;font-size:150%;text-align:center;border-radius:9px 9px; padding: 15px; border-style: solid; border-color: black\">TABLE OF CONTENTS</div>   \n",
        "    \n",
        "* [1. Introduction](#1)\n",
        "    \n",
        "* [2. Import Necessaries](#2)\n",
        "    \n",
        "* [3. EDA](#3)\n",
        "\n",
        "    * [3.1. Define data path and dataset name](#3.1)\n",
        "    * [3.2. Create Dataframe for the dataset](#3.2)\n",
        "    * [3.3. Display Number of Examples in the dataset](#3.3)\n",
        "    * [3.4. Display Number of Classes in the dataset](#3.4)\n",
        "    * [3.5. Display count of images in each class of the dataset](#3.5)\n",
        "    * [3.6. Visualize Each Class in the dataset](#3.6)\n",
        "    * [3.7. Check Null values in the dataframe](#3.7)\n",
        "    * [3.8. Visualize Null values](#3.8)\n",
        "    \n",
        "    \n",
        "* [4. Split dataframe into train, valid, and test](#4)\n",
        "     \n",
        "* [5. Create Image Data Generator](#5)\n",
        "\n",
        "* [6. Visualize Training dataset](#6)\n",
        "\n",
        "* [7. Model Structure](#7)\n",
        "\n",
        "    * [7.1. Generic Model Creation](#7.1)\n",
        "    * [7.2. Define Early Stop](#7.2)\n",
        "    * [7.3. Train model](#7.3)\n",
        "    \n",
        "\n",
        "* [8. Evaluate Model](#8)\n",
        "\n",
        "    * [8.1. Plot accuarcy and loss curve](#8.1)\n",
        "    * [8.2. Model Accuarcy](#8.2)\n",
        "    * [8.3. Get Predictions](#8.3)\n",
        "    \n",
        "\n",
        "* [9. Save the Model](#9)\n",
        "\n",
        "* [10. Load Model and Predict Inputs](#10)\n",
        "\n",
        "* [11. AUTHOR MESSAGE](#12)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-Gd5N5DVxzO"
      },
      "source": [
        "<a id=\"1\"></a>\n",
        "## <b>1 <span style='color:#B21010'>||</span> Introduction</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "flfeKfHgVxzP"
      },
      "source": [
        "\n",
        "<div style=\"border-radius:10px;\n",
        "            border: black solid;\n",
        "            adding: 15px;\n",
        "            background-color:#FBA7A7;\n",
        "            font-size:120%;\n",
        "            text-aling: left\">\n",
        "<h3 style:'border:0; border-radius: 15px; color: black'><center> Steps we will go through:</center></h3>\n",
        "\n",
        "_________________________________________________________________________\n",
        "    \n",
        "Developing a mango leaf disease classifier can be extremely beneficial for agriculture, as it could assist farmers in early detection and management of diseases, ultimately improving crop yield and quality.\n",
        "    \n",
        "we will walk through this steps:\n",
        "    \n",
        "1. Load the data by storing each image path in a list and its corresponding label in another list<br>\n",
        "2. Transform the lists into dataframe<br>\n",
        "3. EDA and analyze the data for more insights\n",
        "4. Split the data into train, test and validation datasets<br>\n",
        "5. Create Data Generator for Train, Test and validation datasets<br>\n",
        "Tensorflow Generators are very useful to Generate batches of tensor image data with real-time data augmentation.<br>\n",
        "6. Load the pretrained model, add some layers on top of its base layer and compile it<br>\n",
        "We will be using EffiecentNet, of course you can use any pretrained model you want and tune its architecture and parameters!<br>\n",
        "7. Evaluate the model by plotting acc and loss curves, plot confussion matrix and print classification report<br>\n",
        "8. Save The model to use it in production\n",
        "9. Load The model and predict inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqY5w28SVxzR"
      },
      "source": [
        "<a id=\"2\"></a>\n",
        "## <b>2 <span style='color:#B21010'>||</span> Import Necessaries</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uvTi4vsqVxzS",
        "outputId": "a92ad70c-c561-46db-8744-0ea1c98dad14"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[3], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adam, Adamax\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m categorical_crossentropy\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/api/_v2/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_v2\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __internal__\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m activations\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m applications\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/__internal__/__init__.py:6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m losses\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizers\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__internal__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/__internal__/models/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"AUTOGENERATED. DO NOT EDIT.\"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone_and_build_model\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m in_place_subclassed_model_state_restoration\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/__init__.py:21\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Implementation of the Keras API, the high-level API of TensorFlow.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03mDetailed documentation and user guides are available at\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m[keras.io](https://keras.io).\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distribute\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minput_layer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Input\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/models/__init__.py:18\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# ==============================================================================\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Functional\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msequential\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtraining\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/engine/functional.py:33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m input_spec\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m node \u001b[38;5;28;01mas\u001b[39;00m node_module\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training \u001b[38;5;28;01mas\u001b[39;00m training_lib\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mengine\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m training_utils\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/engine/training.py:49\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimizer_v1\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pickle_utils\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_api\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization_lib\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/saving/saving_api.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf_export\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_export\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m saving_lib\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m legacy_sm_saving_lib\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m io_utils\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/saving/legacy/save.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m serialization\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load \u001b[38;5;28;01mas\u001b[39;00m saved_model_load\n\u001b[0;32m---> 27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_context\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m save \u001b[38;5;28;01mas\u001b[39;00m saved_model_save\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaving\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msaved_model\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m keras_option_scope\n",
            "File \u001b[0;32m~/anaconda3/envs/GPU/lib/python3.11/site-packages/keras/src/saving/legacy/saved_model/load_context.py:68\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns whether under a load context.\"\"\"\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_context\u001b[38;5;241m.\u001b[39min_load_context()\n\u001b[0;32m---> 68\u001b[0m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mregister_load_context_function(in_load_context)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.compat.v2.__internal__' has no attribute 'register_load_context_function'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import itertools\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from plotly.offline import iplot\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.callbacks import EarlyStopping, LearningRateScheduler\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "from tensorflow.keras.applications import EfficientNetB0, EfficientNetB1, EfficientNetB2, EfficientNetB3, EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
        "\n",
        "# Ignore Warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print ('modules loaded')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUrRFbwxVxzV"
      },
      "source": [
        "<a id=\"3\"></a>\n",
        "## <b>3 <span style='color:#B21010'>||</span> EDA</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl-fsnApVxzX"
      },
      "source": [
        "<a id=\"3.1\"></a>\n",
        "### <b>3.1 <span style='color:#B21010'>||</span> Define data path and dataset name</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qwj5nV7FYgdE"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk3RdcLUVxzY"
      },
      "outputs": [],
      "source": [
        "# data_dir ='/content/drive/MyDrive/RESEARCH/Mango Leaf Disease/MANGO LEAF DESEASE DATASET'\n",
        "data_dir = 'MANGO LEAF DESEASE'\n",
        "# ds_name = 'Mango Leaf Disease'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubnQIr5vVxzY"
      },
      "source": [
        "<a id=\"3.2\"></a>\n",
        "### <b>3.2 <span style='color:#B21010'>||</span> Create Dataframe for the dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3V7_hD9cVxza"
      },
      "outputs": [],
      "source": [
        "# Generate data paths with labels\n",
        "\n",
        "def generate_data_paths(data_dir):\n",
        "\n",
        "    filepaths = []\n",
        "    labels = []\n",
        "\n",
        "    folds = os.listdir(data_dir)\n",
        "    for fold in folds:\n",
        "        foldpath = os.path.join(data_dir, fold)\n",
        "        filelist = os.listdir(foldpath)\n",
        "        for file in filelist:\n",
        "            fpath = os.path.join(foldpath, file)\n",
        "            filepaths.append(fpath)\n",
        "            labels.append(fold)\n",
        "\n",
        "    return filepaths, labels\n",
        "\n",
        "\n",
        "filepaths, labels = generate_data_paths(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dyyYJuZVxzb"
      },
      "outputs": [],
      "source": [
        "def create_df(filepaths, labels):\n",
        "\n",
        "    Fseries = pd.Series(filepaths, name= 'filepaths')\n",
        "    Lseries = pd.Series(labels, name='labels')\n",
        "    df = pd.concat([Fseries, Lseries], axis= 1)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = create_df(filepaths, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHpGX388Vxzb"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUUWqFZGVxzc"
      },
      "source": [
        "<a id=\"3.3\"></a>\n",
        "### <b>3.3 <span style='color:#B21010'>||</span> Display Number of Examples in the dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAJmugNSVxzc"
      },
      "outputs": [],
      "source": [
        "def num_of_examples(df, name='df'):\n",
        "    print(f\"The {name} dataset has {df.shape[0]} images.\")\n",
        "\n",
        "num_of_examples(df, ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q9Q20UGVxzd"
      },
      "source": [
        "<a id=\"3.4\"></a>\n",
        "### <b>3.4 <span style='color:#B21010'>||</span> Display Number of Classes in the dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHKibxnIVxzg"
      },
      "outputs": [],
      "source": [
        "def num_of_classes(df, name='df'):\n",
        "    print(f\"The {name} dataset has {len(df['labels'].unique())} classes\")\n",
        "\n",
        "num_of_classes(df, ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lepBWv3OVxzh"
      },
      "source": [
        "<a id=\"3.5\"></a>\n",
        "### <b>3.5 <span style='color:#B21010'>||</span> Display count of images in each class of the dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8drENVTVxzi"
      },
      "outputs": [],
      "source": [
        "def classes_count(df, name='df'):\n",
        "\n",
        "    print(f\"The {name} dataset has: \")\n",
        "    print(\"=\"*70)\n",
        "    print()\n",
        "    for name in df['labels'].unique():\n",
        "        num_class = len(df['labels'][df['labels'] == name])\n",
        "        print(f\"Class '{name}' has {num_class} images\")\n",
        "        print('-'*70)\n",
        "\n",
        "classes_count(df, ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mtBrSt5Vxzj"
      },
      "source": [
        "<a id=\"3.6\"></a>\n",
        "### <b>3.6 <span style='color:#B21010'>||</span> Visualize Each Class in the dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPSd_303Vxzk"
      },
      "outputs": [],
      "source": [
        "def cat_summary_with_graph(dataframe, col_name):\n",
        "    fig = make_subplots(rows=1, cols=2,\n",
        "                        subplot_titles=('Countplot', 'Percentages'),\n",
        "                        specs=[[{\"type\": \"bar\"}, {'type': 'pie'}]])\n",
        "\n",
        "    fig.add_trace(go.Bar(y=dataframe[col_name].value_counts().values.tolist(),\n",
        "                         x=[str(i) for i in dataframe[col_name].value_counts().index],\n",
        "                         text=dataframe[col_name].value_counts().values.tolist(),\n",
        "                         textfont=dict(size=20),\n",
        "                         name=col_name,\n",
        "                         textposition='auto',\n",
        "                         showlegend=False,\n",
        "                         marker=dict(color=colors)),\n",
        "                  row=1, col=1)\n",
        "\n",
        "    fig.add_trace(go.Pie(labels=dataframe[col_name].value_counts().keys(),\n",
        "                         values=dataframe[col_name].value_counts().values,\n",
        "                         textfont=dict(size=20),\n",
        "                         textposition='auto',\n",
        "                         showlegend=False,\n",
        "                         name=col_name,\n",
        "                         marker=dict(colors=colors)),\n",
        "                  row=1, col=2)\n",
        "\n",
        "    fig.update_layout(title={'text': col_name,\n",
        "                             'y': 0.9,\n",
        "                             'x': 0.5,\n",
        "                             'xanchor': 'center',\n",
        "                             'yanchor': 'top'},\n",
        "                      template='plotly_white')\n",
        "\n",
        "    iplot(fig)\n",
        "\n",
        "\n",
        "colors = ['#494BD3', '#E28AE2', '#F1F481', '#79DB80', '#DF5F5F',\n",
        "              '#69DADE', '#C2E37D', '#E26580', '#D39F49', '#B96FE3']\n",
        "\n",
        "cat_summary_with_graph(df,'labels')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3K4E1jeGVxzl"
      },
      "source": [
        "<a id=\"3.7\"></a>\n",
        "### <b>3.7 <span style='color:#B21010'>||</span> Check Null values in the dataframe</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C-2iX2O7Vxzl"
      },
      "outputs": [],
      "source": [
        "def check_null_values(df, name='df'):\n",
        "\n",
        "    num_null_vals = sum(df.isnull().sum().values)\n",
        "\n",
        "    if not num_null_vals:\n",
        "        print(f\"The {name} dataset has no null values\")\n",
        "\n",
        "    else:\n",
        "        print(f\"The {name} dataset has {num_null_vals} null values\")\n",
        "        print('-'*70)\n",
        "        print('Total null values in each column:\\n')\n",
        "        print(df.isnull().sum())\n",
        "\n",
        "\n",
        "check_null_values(df, ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJqFsuA4Vxzm"
      },
      "source": [
        "<a id=\"3.8\"></a>\n",
        "### <b>3.8 <span style='color:#B21010'>||</span> Visualize Null values</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t90Q_nQZVxzm"
      },
      "outputs": [],
      "source": [
        "msno.matrix(df)\n",
        "plt.title('Distribution of Missing Values', fontsize=30, fontstyle='oblique');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muiHkYEIVxzm"
      },
      "source": [
        "<a id=\"4\"></a>\n",
        "## <b>4 <span style='color:#B21010'>||</span>Split dataframe into train, valid, and test</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fh12UZdaVxzn"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg81BhOfVxzn"
      },
      "outputs": [],
      "source": [
        "# train dataframe\n",
        "train_df, dummy_df = train_test_split(df,  train_size= 0.7, shuffle= True, random_state= 123)\n",
        "\n",
        "# valid and test dataframe\n",
        "valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 123)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTD70UEdVxzn"
      },
      "outputs": [],
      "source": [
        "def num_imgs(df, name='df'):\n",
        "    print(f\"Number of {name} dataset is {len(df)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYSrYRodVxzo"
      },
      "outputs": [],
      "source": [
        "num_imgs(train_df, 'Training '+ds_name)\n",
        "num_imgs(valid_df, 'Validation '+ds_name)\n",
        "num_imgs(test_df, 'Testing '+ds_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fqfkHWJVxzo"
      },
      "outputs": [],
      "source": [
        "num_of_classes(train_df, \"Training \"+ds_name)\n",
        "num_of_classes(valid_df, \"Validation \"+ds_name)\n",
        "num_of_classes(test_df, \"Testing \"+ds_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8LahagjVxzo"
      },
      "outputs": [],
      "source": [
        "classes_count(train_df, 'Training '+ds_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAw27C9cVxzp"
      },
      "outputs": [],
      "source": [
        "classes_count(valid_df, 'Validation '+ds_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u7FrpBXVxzp"
      },
      "outputs": [],
      "source": [
        "classes_count(test_df, 'Testing '+ds_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTvtUIn_Vxzq"
      },
      "source": [
        "<a id=\"5\"></a>\n",
        "## <b>5 <span style='color:#B21010'>||</span>Create Image Data Generator</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTfsBIuVVxzr"
      },
      "outputs": [],
      "source": [
        "# crobed image size\n",
        "batch_size = 40\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "\n",
        "# Recommended : use custom function for test data batch size, else we can use normal batch size.\n",
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "# This function which will be used in image data generator for data augmentation, it just takes the image and return it again.\n",
        "def scalar(img):\n",
        "    return img\n",
        "\n",
        "tr_gen = ImageDataGenerator(preprocessing_function= scalar,\n",
        "                           rotation_range=40,\n",
        "                           width_shift_range=0.2,\n",
        "                           height_shift_range=0.2,\n",
        "                           brightness_range=[0.4,0.6],\n",
        "                           zoom_range=0.3,\n",
        "                           horizontal_flip=True,\n",
        "                           vertical_flip=True)\n",
        "\n",
        "ts_gen = ImageDataGenerator(preprocessing_function= scalar,\n",
        "                           rotation_range=40,\n",
        "                           width_shift_range=0.2,\n",
        "                           height_shift_range=0.2,\n",
        "                           brightness_range=[0.4,0.6],\n",
        "                           zoom_range=0.3,\n",
        "                           horizontal_flip=True,\n",
        "                           vertical_flip=True)\n",
        "\n",
        "train_gen = tr_gen.flow_from_dataframe(train_df,\n",
        "                                       x_col = 'filepaths',\n",
        "                                       y_col= 'labels',\n",
        "                                       target_size = img_size,\n",
        "                                       class_mode= 'categorical',\n",
        "                                       color_mode= 'rgb',\n",
        "                                       shuffle= True,\n",
        "                                       batch_size=batch_size)\n",
        "\n",
        "valid_gen = ts_gen.flow_from_dataframe(valid_df,\n",
        "                                       x_col= 'filepaths',\n",
        "                                       y_col= 'labels',\n",
        "                                       target_size= img_size,\n",
        "                                       class_mode= 'categorical',\n",
        "                                       color_mode= 'rgb',\n",
        "                                       shuffle= True,\n",
        "                                       batch_size= batch_size)\n",
        "\n",
        "# Note: we will use custom test_batch_size, and make shuffle= false\n",
        "test_gen = ts_gen.flow_from_dataframe(test_df,\n",
        "                                      x_col= 'filepaths',\n",
        "                                      y_col= 'labels',\n",
        "                                      target_size= img_size,\n",
        "                                      class_mode= 'categorical',\n",
        "                                      color_mode= 'rgb',\n",
        "                                      shuffle= False,\n",
        "                                      batch_size= test_batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSTd1v1VVxzs"
      },
      "source": [
        "<a id=\"6\"></a>\n",
        "## <b>6 <span style='color:#B21010'>||</span>Visualize Training dataset</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJpvW0w3Vxzs"
      },
      "outputs": [],
      "source": [
        "g_dict = train_gen.class_indices      # defines dictionary {'class': index}\n",
        "classes = list(g_dict.keys())       # defines list of dictionary's kays (classes), classes names : string\n",
        "images, labels = next(train_gen)      # get a batch size samples from the generator\n",
        "\n",
        "plt.figure(figsize= (20, 20))\n",
        "\n",
        "for i in range(16):\n",
        "\n",
        "    plt.subplot(4, 4, i + 1)\n",
        "    image = images[i] / 255       # scales data to range (0 - 255)\n",
        "    plt.imshow(image)\n",
        "    index = np.argmax(labels[i])  # get image index\n",
        "    class_name = classes[index]   # get class of image\n",
        "    plt.title(class_name, color= 'blue', fontsize= 15)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLszWAMiVxzu"
      },
      "source": [
        "<a id=\"7\"></a>\n",
        "## <b>7 <span style='color:#B21010'>||</span>Model Structure</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBhyK1jnVxzu"
      },
      "source": [
        "<a id=\"7.1\"></a>\n",
        "### <b>7.1 <span style='color:#B21010'>||</span>Generic Model Creation</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5d8R-O65Vxzv"
      },
      "outputs": [],
      "source": [
        "# Create Model Structure\n",
        "img_size = (224, 224)\n",
        "channels = 3\n",
        "img_shape = (img_size[0], img_size[1], channels)\n",
        "class_count = len(list(train_gen.class_indices.keys())) # to define number of classes in dense layer\n",
        "\n",
        "# create pre-trained model (you can built on pretrained model such as :  efficientnet, VGG , Resnet )\n",
        "# we will use efficientnetb7 from EfficientNet family.\n",
        "\n",
        "base_model = tf.keras.applications.efficientnet.EfficientNetB7(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')\n",
        "base_model.trainable = False\n",
        "\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n",
        "    Dense(128,kernel_regularizer= regularizers.l2(l= 0.016), activity_regularizer= regularizers.l1(0.006),\n",
        "                bias_regularizer= regularizers.l1(0.006), activation = 'relu'),\n",
        "    Dropout(rate= 0.45, seed= 123),\n",
        "    Dense(class_count, activation= 'softmax')\n",
        "])\n",
        "\n",
        "model.compile(Adamax(learning_rate = 0.001), loss = 'categorical_crossentropy', metrics= ['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOHvfWaPVxzx"
      },
      "source": [
        "<a id=\"7.2\"></a>\n",
        "### <b>7.2 <span style='color:#B21010'>||</span>Define Early Stop</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkUEtBq_Vxzx"
      },
      "outputs": [],
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss',\n",
        "                               patience=5,\n",
        "                               restore_best_weights=True,\n",
        "                               mode='min',\n",
        "                              )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQAD6p6QVxzy"
      },
      "source": [
        "<a id=\"7.3\"></a>\n",
        "### <b>7.3 <span style='color:#B21010'>||</span>Train Model</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gu1oNXsYVxzz"
      },
      "outputs": [],
      "source": [
        "batch_size = 16   # set batch size for training\n",
        "epochs = 50   # number of all epochs in training\n",
        "\n",
        "history = model.fit(x=train_gen,\n",
        "                    epochs = epochs,\n",
        "                    verbose = 1,\n",
        "                    validation_data = valid_gen,\n",
        "                    validation_steps = None,\n",
        "                    shuffle = False,\n",
        "                    batch_size = batch_size,\n",
        "                    callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9c43WYDVxz0"
      },
      "source": [
        "<a id=\"8\"></a>\n",
        "## <b>8 <span style='color:#B21010'>||</span>Evaluate Model</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my-vjPkxVxz0"
      },
      "source": [
        "<a id=\"8.1\"></a>\n",
        "### <b>8.1 <span style='color:#B21010'>||</span>Plot accuracy and loss curve </b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xZz_ALyVxz0"
      },
      "outputs": [],
      "source": [
        "# Define needed variables\n",
        "tr_acc = history.history['accuracy']\n",
        "tr_loss = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "index_loss = np.argmin(val_loss)\n",
        "val_lowest = val_loss[index_loss]\n",
        "index_acc = np.argmax(val_acc)\n",
        "acc_highest = val_acc[index_acc]\n",
        "Epochs = [i+1 for i in range(len(tr_acc))]\n",
        "loss_label = f'best epoch= {str(index_loss + 1)}'\n",
        "acc_label = f'best epoch= {str(index_acc + 1)}'\n",
        "\n",
        "# Plot training history\n",
        "\n",
        "plt.figure(figsize= (20, 8))\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(Epochs, tr_loss, 'r', label= 'Training loss')\n",
        "plt.plot(Epochs, val_loss, 'g', label= 'Validation loss')\n",
        "plt.scatter(index_loss + 1, val_lowest, s= 150, c= 'blue', label= loss_label)\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(Epochs, tr_acc, 'r', label= 'Training Accuracy')\n",
        "plt.plot(Epochs, val_acc, 'g', label= 'Validation Accuracy')\n",
        "plt.scatter(index_acc + 1 , acc_highest, s= 150, c= 'blue', label= acc_label)\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtAHeN4RVxz1"
      },
      "source": [
        "<a id=\"8.2\"></a>\n",
        "### <b>8.2 <span style='color:#B21010'>||</span>Model Accuracy</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7POrL9MGVxz1"
      },
      "outputs": [],
      "source": [
        "ts_length = len(test_df)\n",
        "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
        "test_steps = ts_length // test_batch_size\n",
        "\n",
        "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
        "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
        "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
        "\n",
        "print(\"Train Loss: \", train_score[0])\n",
        "print(\"Train Accuracy: \", train_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Validation Loss: \", valid_score[0])\n",
        "print(\"Validation Accuracy: \", valid_score[1])\n",
        "print('-' * 20)\n",
        "print(\"Test Loss: \", test_score[0])\n",
        "print(\"Test Accuracy: \", test_score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4vOUpk6Vxz2"
      },
      "source": [
        "<a id=\"8.3\"></a>\n",
        "### <b>8.3 <span style='color:#B21010'>||</span>Get Prediction</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQYWKYbuVxz2"
      },
      "outputs": [],
      "source": [
        "preds = model.predict_generator(test_gen)\n",
        "y_pred = np.argmax(preds, axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLF7K37aVxz3"
      },
      "source": [
        "<a id=\"8.4\"></a>\n",
        "### <b>8.4 <span style='color:#B21010'>||</span>Confusion Matrix</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwYnzCeNVxz3"
      },
      "outputs": [],
      "source": [
        "g_dict = test_gen.class_indices\n",
        "classes = list(g_dict.keys())\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_gen.classes, y_pred)\n",
        "\n",
        "plt.figure(figsize= (10, 10))\n",
        "plt.imshow(cm, interpolation= 'nearest', cmap= plt.cm.Blues)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.colorbar()\n",
        "\n",
        "tick_marks = np.arange(len(classes))\n",
        "plt.xticks(tick_marks, classes, rotation= 45)\n",
        "plt.yticks(tick_marks, classes)\n",
        "\n",
        "\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb8MWxpMVxz4"
      },
      "source": [
        "<a id=\"8.5\"></a>\n",
        "### <b>8.5 <span style='color:#B21010'>||</span>Classification Report</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7P3QVvgVxz4"
      },
      "outputs": [],
      "source": [
        "# Classification report\n",
        "print(classification_report(test_gen.classes, y_pred, target_names= classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FEbl7YnVxz4"
      },
      "source": [
        "<a id=\"9\"></a>\n",
        "## <b>9 <span style='color:#B21010'>||</span>Save the Model</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfHTmyosVxz5"
      },
      "outputs": [],
      "source": [
        "model.save_weights('my_model_weights.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H2r0XJHVxz5"
      },
      "source": [
        "<a id=\"10\"></a>\n",
        "## <b>10 <span style='color:#B21010'>||</span>Load the model and Predict the Inputs</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmHN4tXcVxz5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
        "\n",
        "def predict_and_display(image_path, model, class_labels):\n",
        "\n",
        "    img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    predicted_class_index = np.argmax(prediction)\n",
        "\n",
        "    predicted_class_label = class_labels[predicted_class_index]\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.title(f\"Predicted Vehicle: {predicted_class_label}\")\n",
        "    plt.show()\n",
        "\n",
        "# Load your trained model\n",
        "model.load_weights('/kaggle/working/my_model_weights.h5')\n",
        "\n",
        "# Define your class labels (e.g., ['car', 'truck', ...])\n",
        "class_labels = list(train_gen.class_indices.keys())\n",
        "\n",
        "# Replace 'path_to_test_image' with the path to the image you want to test\n",
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Anthracnose/20211008_124253 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejeAYZKYVxz6"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Bacterial Canker/IMG_20211106_120951 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SRj6A16oVxz7"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Cutting Weevil/20211011_160708 (Custom) (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E39guWO1Vxz7"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Die Back/20211129_160627 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASqSesapVxz8"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Gall Midge/IMG_20211106_161226 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXBUHBkGVxz9"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Healthy/20211231_123625 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOjyqGGaVxz9"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Powdery Mildew/20211109_121452 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HwzG5HxVxz-"
      },
      "outputs": [],
      "source": [
        "image_path_to_test = '/kaggle/input/mango-leaf-disease-dataset/MangoLeafBD Dataset/Sooty Mould/IMG_20211108_121234 (Custom).jpg'\n",
        "predict_and_display(image_path_to_test, model, class_labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_H2r0XJHVxz5"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4083779,
          "sourceId": 7087651,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30587,
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}